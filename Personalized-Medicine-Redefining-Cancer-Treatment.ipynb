{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Classify Genetic Variations using Text from Clinical Evidence\n",
    "A team at Memorial Sloan Kettering Cancer Center (MSKCC) spends countless hours every year manually reviewing evidence to classify genetic mutations. Once the most important variants have been identified new therapies can be developed. Having a machine learning algorithm to automatically classify genetic variations would allow the development of therapies much sooner. This competition is a challenge to develop classification models which analyze abstracts of medical articles and, based on their content accurately determine mutation effect (9 classes) of the genes discussed in them. For more information, please refer to the Kaggle competition: https://www.kaggle.com/c/msk-redefining-cancer-treatment#description. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an article that also gives context to a project such as this and the impact could have: https://www.forbes.com/sites/matthewherper/2017/06/03/a-new-cancer-drug-helped-almost-everyone-who-took-it-almost-heres-what-it-teaches-us/#12aad9136b25. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is complex and hard to elvaluate the cross val score due to the data only representing some of the genes in the dataset. In the end, if my score is not great, I hope to have been able to better understand the use of machine learning in genomic analysis and explore its limitations. \n",
    "\n",
    "\n",
    "Also, there was a 2nd phase to this competition due to the labels for the test data being released by a third party before the competition closed. I may want to combine the training data from both phases to train the model if I am not able to get a good score from just the initial data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target: 9 classes that represent different levels of whether or not the variant is a driver or passenger mutation.\n",
    "These are the class labels from OncoKB, but using this text in the competition is prohibited. \n",
    "1. Likely Loss-of-function\n",
    "2. Likely Gain-of-function\n",
    "3. Neutral\n",
    "4. Loss-of-function\n",
    "5. Likely Neutral\n",
    "6. Inconclusive\n",
    "7. Gain-of-function\n",
    "8. Likely Switch-of-function\n",
    "9. Switch-of-function\n",
    "\n",
    "Using COSMIC and Genotype-Phenotype associations are not allowed due to the point of this project being modeling text.\n",
    "\n",
    "You are not allowed to use conservation scores, or predictors of deleterious or tolerated mutations (such as Polyphen) because these tools also try to predict the effect of a mutation (which is very close to the goal of this competition) but they don't use text to do it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outside resources that have been approved by kaggle for use in this competition but not necessary:\n",
    " -  Gene–disease associations: http://ctdbase.org/\n",
    " -  Text data from:\n",
    "    - Encyclopedia_of_Molecular_Cell_Biology_and_Molecular_Medicine_16_volumes_Wiley_2006_\n",
    "    - Cell-Molecular-Biology-Concepts-Experiments 7th edition\n",
    " - MESH topics, as well as extended information about those articles\n",
    " - Pre-trained Bio-NER taggers (May need to map the variations to RSIDs and search related articles in PubMed or PMC):\n",
    "    - tmVar https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/tmvar/\n",
    "    - TaggerOne https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/taggerone/\n",
    "    - GNormPlus https://www.ncbi.nlm.nih.gov/research/bionlp/Tools/gnormplus/\n",
    " - Pathway and protein information of each gene (e.g. GO).\n",
    " - Pubmed dictionaries of genes names.\n",
    " - Mygene api (http://docs.mygene.info/en/v3/doc/data.html) It contains a lot of information about genes (such as family, overall description, etc). \n",
    " - Gene expression from The Human Protein Atlas project ( https://www.ebi.ac.uk/gxa/experiments/E-PROT-3/Downloads )\n",
    " - The aminoacid sequences for the genes in the dataset, in FASTA.\n",
    " - Other papers from PubMed in addition to the training_text in order to pre-train NLP model\n",
    " - Genia, an annotated treebank for parsing biomed papers(http://www.geniaproject.org/)\n",
    " - You can use variations themselves as features. For example a 'Deletion' in a gene may be more likely to be 1. Similar case could be made for amino acid changes. Some amino acid changes are more deleterious than others.\n",
    " - Google's trained Word2Vec models and pretrained models from bio.nlplab.org\n",
    " - Sequence data, mutation positition data and protein structure data from Uniport\n",
    " - allele frequency information from gnomAD or ExAC\n",
    " - controlled vocabularies to guide Named Entity Recognition modles. Examples: such as ICD, SNOMED CT,NCI Thesaurus, CPT, MedDRA, SNOMED CT\n",
    " \n",
    " Note from Kaggle: \"We knew the task was very difficult, so Iker from MSK suggested that we allow external data, in case anyone wants to build a knowledge base for gene mutations.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, \\\n",
    "HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline, make_union\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_var = pd.read_csv('Data/training_variants.zip')\n",
    "train_txt = pd.read_csv('Data/training_text.zip', sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n",
    "test_var = pd.read_csv('Data/test_variants.zip')\n",
    "test_txt = pd.read_csv('Data/test_text.zip', sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 4)\n",
      "ID            int64\n",
      "Gene         object\n",
      "Variation    object\n",
      "Class         int64\n",
      "dtype: object\n",
      "ID           0\n",
      "Gene         0\n",
      "Variation    0\n",
      "Class        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_var.shape)\n",
    "print(train_var.dtypes)\n",
    "print(train_var.isnull().sum())\n",
    "train_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BRCA1</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP53</th>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGFR</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTEN</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRCA2</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIT</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRAF</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALK</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERBB2</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDGFRA</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIK3CA</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDKN2A</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR2</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLT3</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSC2</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MTOR</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KRAS</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP2K1</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VHL</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RET</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGFR3</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLH1</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MET</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAD4</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAK2</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOTCH1</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AKT1</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROS1</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTPN11</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABL1</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMT2B</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUSP4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTLA4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IKBKE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RRAS2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEGFA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAK1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INPP4B</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FANCC</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOC2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATS1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCF7L2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCF3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDM4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RARA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD51B</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDKN2C</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAG2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARD1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FUBP1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHSC1L1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JUN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNF43</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDK8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCOR1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERRFI1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLT1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASXL1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLA-B</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GNAQ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gene\n",
       "BRCA1     264\n",
       "TP53      163\n",
       "EGFR      141\n",
       "PTEN      126\n",
       "BRCA2     125\n",
       "KIT        99\n",
       "BRAF       93\n",
       "ALK        69\n",
       "ERBB2      69\n",
       "PDGFRA     60\n",
       "PIK3CA     56\n",
       "CDKN2A     52\n",
       "FGFR2      50\n",
       "FLT3       49\n",
       "TSC2       47\n",
       "MTOR       45\n",
       "KRAS       44\n",
       "MAP2K1     43\n",
       "VHL        41\n",
       "RET        40\n",
       "FGFR3      39\n",
       "MLH1       35\n",
       "MET        33\n",
       "SMAD4      33\n",
       "JAK2       33\n",
       "NOTCH1     31\n",
       "AKT1       28\n",
       "ROS1       26\n",
       "PTPN11     26\n",
       "ABL1       26\n",
       "...       ...\n",
       "KMT2B       1\n",
       "DUSP4       1\n",
       "CTLA4       1\n",
       "IKBKE       1\n",
       "RRAS2       1\n",
       "VEGFA       1\n",
       "PAK1        1\n",
       "INPP4B      1\n",
       "FANCC       1\n",
       "SHOC2       1\n",
       "LATS1       1\n",
       "TCF7L2      1\n",
       "TCF3        1\n",
       "MDM4        1\n",
       "RARA        1\n",
       "RAD51B      1\n",
       "CDKN2C      1\n",
       "STAG2       1\n",
       "BARD1       1\n",
       "FUBP1       1\n",
       "WHSC1L1     1\n",
       "JUN         1\n",
       "RNF43       1\n",
       "CDK8        1\n",
       "NCOR1       1\n",
       "ERRFI1      1\n",
       "FLT1        1\n",
       "ASXL1       1\n",
       "HLA-B       1\n",
       "GNAQ        1\n",
       "\n",
       "[264 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_var['Gene'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Truncating Mutations</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deletion</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amplification</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fusions</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overexpression</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G12V</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q61L</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q61H</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E17K</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q61R</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T58I</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q209L</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMPRSS2-ETV1 Fusion</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G13D</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P34R</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T286A</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S308A</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T167A</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E542K</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y42C</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G13C</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A146V</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F28L</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R173C</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promoter Hypermethylation</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G13V</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G12A</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K117N</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C618R</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EWSR1-ETV1 Fusion</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S241L</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M552_K558del</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E76A</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCM1-JAK2 Fusion</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P531S</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T205A</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P278L</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G623R</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P491S</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S276L</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2418G</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2106P</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T80K</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E82G</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F341C</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHTOP-NTRK1 Fusion</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP85L-ROS1 Fusion</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R683K</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q337*</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D74Y</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1722F</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I130M</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E120Q</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C41Y</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S123T</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S387N</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y236D</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H870R</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N1819Y</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P417A</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Variation\n",
       "Truncating Mutations              93\n",
       "Deletion                          74\n",
       "Amplification                     71\n",
       "Fusions                           34\n",
       "Overexpression                     6\n",
       "G12V                               4\n",
       "Q61L                               3\n",
       "Q61H                               3\n",
       "E17K                               3\n",
       "Q61R                               3\n",
       "T58I                               3\n",
       "Q209L                              2\n",
       "TMPRSS2-ETV1 Fusion                2\n",
       "G13D                               2\n",
       "P34R                               2\n",
       "T286A                              2\n",
       "S308A                              2\n",
       "T167A                              2\n",
       "E542K                              2\n",
       "Y42C                               2\n",
       "G13C                               2\n",
       "A146V                              2\n",
       "F28L                               2\n",
       "R173C                              2\n",
       "Promoter Hypermethylation          2\n",
       "G13V                               2\n",
       "G12A                               2\n",
       "K117N                              2\n",
       "C618R                              2\n",
       "EWSR1-ETV1 Fusion                  2\n",
       "...                              ...\n",
       "S241L                              1\n",
       "M552_K558del                       1\n",
       "E76A                               1\n",
       "PCM1-JAK2 Fusion                   1\n",
       "P531S                              1\n",
       "T205A                              1\n",
       "P278L                              1\n",
       "G623R                              1\n",
       "P491S                              1\n",
       "S276L                              1\n",
       "R2418G                             1\n",
       "L2106P                             1\n",
       "T80K                               1\n",
       "E82G                               1\n",
       "F341C                              1\n",
       "CHTOP-NTRK1 Fusion                 1\n",
       "CEP85L-ROS1 Fusion                 1\n",
       "R683K                              1\n",
       "Q337*                              1\n",
       "D74Y                               1\n",
       "S1722F                             1\n",
       "I130M                              1\n",
       "E120Q                              1\n",
       "C41Y                               1\n",
       "S123T                              1\n",
       "S387N                              1\n",
       "Y236D                              1\n",
       "H870R                              1\n",
       "N1819Y                             1\n",
       "P417A                              1\n",
       "\n",
       "[2996 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_var['Variation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    953\n",
       "4    686\n",
       "1    568\n",
       "2    452\n",
       "6    275\n",
       "5    242\n",
       "3     89\n",
       "9     37\n",
       "8     19\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_var['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njoiIqCXBERERtfx/GnZRbZUqeCMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bf2a9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.countplot(x=\"Class\", data=train_var)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.title(\"Distribution of genetic mutation classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking at the genes with 50 or more occurances in the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    90\n",
      "1    60\n",
      "6    53\n",
      "4    46\n",
      "3    15\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BRCA1\n",
    "BRCA1 = train_var.loc[train_var['Gene']=='BRCA1']\n",
    "print(BRCA1['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    83\n",
      "4    67\n",
      "6     5\n",
      "2     3\n",
      "5     2\n",
      "3     2\n",
      "9     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TP53\n",
    "TP53 = train_var.loc[train_var['Gene']=='TP53']\n",
    "print(TP53['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    84\n",
      "2    45\n",
      "4     5\n",
      "5     3\n",
      "8     1\n",
      "6     1\n",
      "3     1\n",
      "1     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# EGFR\n",
    "EGFR = train_var.loc[train_var['Gene']=='EGFR']\n",
    "print(EGFR['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    115\n",
      "3      5\n",
      "1      3\n",
      "5      2\n",
      "7      1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# PTEN\n",
    "PTEN = train_var.loc[train_var['Gene']=='PTEN']\n",
    "print(PTEN['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6    84\n",
      "5    20\n",
      "1    18\n",
      "4     3\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BRCA2\n",
    "BRCA2 = train_var.loc[train_var['Gene']=='BRCA2']\n",
    "print(BRCA2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    52\n",
      "2    44\n",
      "6     1\n",
      "4     1\n",
      "3     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# KIT\n",
    "KIT = train_var.loc[train_var['Gene']=='KIT']\n",
    "print(KIT['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    48\n",
      "2    31\n",
      "5     8\n",
      "6     3\n",
      "4     2\n",
      "3     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# BRAF\n",
    "BRAF = train_var.loc[train_var['Gene']=='BRAF']\n",
    "print(BRAF['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    30\n",
      "2    14\n",
      "6    12\n",
      "5     6\n",
      "4     5\n",
      "8     1\n",
      "1     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ERBB2\n",
    "ERBB2 = train_var.loc[train_var['Gene']=='ERBB2']\n",
    "print(ERBB2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    47\n",
      "3    10\n",
      "2     7\n",
      "5     5\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ALK\n",
    "ALK = train_var.loc[train_var['Gene']=='ALK']\n",
    "print(ALK['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    42\n",
      "3     9\n",
      "5     4\n",
      "2     3\n",
      "4     1\n",
      "1     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# PDGFRA\n",
    "PDGFRA = train_var.loc[train_var['Gene']=='PDGFRA']\n",
    "print(PDGFRA['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    31\n",
      "2    14\n",
      "5     8\n",
      "6     3\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# PIK3CA\n",
    "PIK3CA = train_var.loc[train_var['Gene']=='PIK3CA']\n",
    "print(PIK3CA['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    47\n",
      "1     4\n",
      "6     1\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CDKN2A\n",
    "CDKN2A = train_var.loc[train_var['Gene']=='CDKN2A']\n",
    "print(CDKN2A['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7    27\n",
      "2     7\n",
      "1     7\n",
      "5     5\n",
      "6     4\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# FGFR2\n",
    "FGFR2 = train_var.loc[train_var['Gene']=='FGFR2']\n",
    "print(FGFR2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Training Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3321, 2)\n",
      "ID      0\n",
      "Text    5\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
       "1   1   Abstract Background  Non-small cell lung canc...\n",
       "2   2   Abstract Background  Non-small cell lung canc...\n",
       "3   3  Recent evidence has demonstrated that acquired...\n",
       "4   4  Oncogenic mutations in the monomeric Casitas B..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_txt.shape)\n",
    "print(train_txt.isnull().sum())\n",
    "train_txt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Test Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5668, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ACSL4</td>\n",
       "      <td>R570S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NAGLU</td>\n",
       "      <td>P521L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PAH</td>\n",
       "      <td>L333F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ING1</td>\n",
       "      <td>A148D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TMEM216</td>\n",
       "      <td>G77A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Gene Variation\n",
       "0   0    ACSL4     R570S\n",
       "1   1    NAGLU     P521L\n",
       "2   2      PAH     L333F\n",
       "3   3     ING1     A148D\n",
       "4   4  TMEM216      G77A"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_var.shape)\n",
    "test_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID            int64\n",
      "Gene         object\n",
      "Variation    object\n",
      "dtype: object\n",
      "ID           0\n",
      "Gene         0\n",
      "Variation    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_var.dtypes)\n",
    "print(test_var.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Test Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5668, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2. This mutation resulted in a myeloproliferat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract The Large Tumor Suppressor 1 (LATS1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vascular endothelial growth factor receptor (V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Inflammatory myofibroblastic tumor (IMT) is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abstract Retinoblastoma is a pediatric retina...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  2. This mutation resulted in a myeloproliferat...\n",
       "1   1   Abstract The Large Tumor Suppressor 1 (LATS1)...\n",
       "2   2  Vascular endothelial growth factor receptor (V...\n",
       "3   3  Inflammatory myofibroblastic tumor (IMT) is a ...\n",
       "4   4   Abstract Retinoblastoma is a pediatric retina..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_txt.shape)\n",
    "test_txt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID       int64\n",
      "Text    object\n",
      "dtype: object\n",
      "ID      0\n",
      "Text    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_txt.dtypes)\n",
    "print(test_txt.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Merge Test text and var dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_var.merge(test_txt, on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Gene         0\n",
       "Variation    0\n",
       "Text         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Gene         0\n",
       "Variation    0\n",
       "Text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum() # shows that null value was dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining variant and text training dataframes, drop null rows, and then split into X and y. Will need to get dummies to create a sparse matrix for a multiclass target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_var.merge(train_txt, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Gene         0\n",
       "Variation    0\n",
       "Class        0\n",
       "Text         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "Gene         0\n",
       "Variation    0\n",
       "Class        0\n",
       "Text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # shows that null value was dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gene             Variation  \\\n",
       "0  FAM58A  Truncating Mutations   \n",
       "1     CBL                 W802*   \n",
       "2     CBL                 Q249E   \n",
       "3     CBL                 N454D   \n",
       "4     CBL                 L399V   \n",
       "\n",
       "                                                Text  \n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...  \n",
       "1   Abstract Background  Non-small cell lung canc...  \n",
       "2   Abstract Background  Non-small cell lung canc...  \n",
       "3  Recent evidence has demonstrated that acquired...  \n",
       "4  Oncogenic mutations in the monomeric Casitas B...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Gene', 'Variation', 'Text']]\n",
    "# X = pd.get_dummies(X, prefix=['gene', 'var'], prefix_sep='', columns=['Gene', 'Variation'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "print(y.shape)\n",
    "# y = pd.get_dummies(y, prefix='class', prefix_sep='', columns=['Class'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes \n",
      "X: (3316, 3) \n",
      "y: (3316,) \n",
      "X_train: (2221, 3) \n",
      "X_test: (1095, 3) \n",
      "y_train: (2221,) \n",
      "y_test: (1095,)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes', '\\n'\n",
    "      'X:',X.shape,'\\n'\n",
    "      'y:',y.shape,'\\n'\n",
    "      'X_train:',X_train.shape, '\\n'\n",
    "      'X_test:',X_test.shape,'\\n' \n",
    "      'y_train:',y_train.shape,'\\n' \n",
    "      'y_test:',y_test.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>BRCA1</td>\n",
       "      <td>E1250K</td>\n",
       "      <td>Mutations in BRCA1 and BRCA2 account for the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>PTPN11</td>\n",
       "      <td>Deletion</td>\n",
       "      <td>PTPN11, which encodes tyrosine phosphatase Shp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>SMO</td>\n",
       "      <td>D473G</td>\n",
       "      <td>The Hedgehog (Hh) signaling pathway is inappro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>PTEN</td>\n",
       "      <td>F341V</td>\n",
       "      <td>We screened mutations of two major tumor suppr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>EGFR</td>\n",
       "      <td>E746_S752delinsA</td>\n",
       "      <td>Non–small-cell lung cancer is the leading caus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gene         Variation  \\\n",
       "2660   BRCA1            E1250K   \n",
       "2368  PTPN11          Deletion   \n",
       "1917     SMO             D473G   \n",
       "2207    PTEN             F341V   \n",
       "262     EGFR  E746_S752delinsA   \n",
       "\n",
       "                                                   Text  \n",
       "2660  Mutations in BRCA1 and BRCA2 account for the m...  \n",
       "2368  PTPN11, which encodes tyrosine phosphatase Shp...  \n",
       "1917  The Hedgehog (Hh) signaling pathway is inappro...  \n",
       "2207  We screened mutations of two major tumor suppr...  \n",
       "262   Non–small-cell lung cancer is the leading caus...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Accepts a single column and returns the column as a numpy array.\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    One-hot-encodes a categorical (string) column.\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.values = None\n",
    "        \n",
    "    def _create_values(self, indices):\n",
    "        return {ind: i+1 for i, ind in enumerate(indices)}\n",
    "    \n",
    "    def _apply_values(self, row_val):\n",
    "        return self.values.get(row_val, 0)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.values = self._create_values(X[self.column].value_counts().index)\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        col = X[self.column].apply(self._apply_values)\n",
    "        return col.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pipe = make_pipeline(\n",
    "#     FeatureExtractor('Text'),\n",
    "#     CountVectorizer(stop_words='english'),\n",
    "#     FunctionTransformer(lambda x: x.todense(), accept_sparse=True) # Takes the sparse matrix that CountVectorizer \n",
    "# )                                                                  # spits out and changes it back into a dense \n",
    "#                                                                    # matrix for the feature union.\n",
    "# gene_pipe = make_pipeline(\n",
    "#     FeatureExtractor('Gene'),\n",
    "#     CategoricalExtractor('Gene'),\n",
    "#     FunctionTransformer(lambda x: x.reshape(-1, 1)) # Takes the data coming out of FeatureExtractor (which is shape\n",
    "# )                                                   # (nrows, ) and changes it to be shape (nrows, 1)) which we \n",
    "#                                                     # need for the feature union.\n",
    "\n",
    "# var_pipe = make_pipeline(\n",
    "#     FeatureExtractor('Variation'), \n",
    "#     CategoricalExtractor('Variation'),\n",
    "#     FunctionTransformer(lambda x: x.reshape(-1, 1))\n",
    "# )\n",
    "\n",
    "# fu = make_union(text_pipe, gene_pipe, var_pipe)\n",
    "\n",
    "# model_pipe = make_pipeline(\n",
    "#     fu,\n",
    "#     RandomForestClassifier()\n",
    "# )\n",
    "\n",
    "text_pipe = make_pipeline(\n",
    "FeatureExtractor('Text'),\n",
    "CountVectorizer(stop_words='english'),\n",
    "FunctionTransformer(lambda x: x.todense(), accept_sparse=True)\n",
    ")\n",
    "\n",
    "gene_pipe = make_pipeline(\n",
    "CategoricalExtractor('Gene'),\n",
    "OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "var_pipe = make_pipeline(\n",
    "CategoricalExtractor('Variation'),\n",
    "OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "fu = make_union(text_pipe, gene_pipe, var_pipe)\n",
    "\n",
    "model_pipe = make_pipeline(\n",
    "fu,\n",
    "OneVsRestClassifier(estimator=SVC(probability=True))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting model on only part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('featureextractor', FeatureExtractor(column='Text')), ('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'...bability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train[:200], y_train[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print(model_pipe.score(X_train[:200], y_train[:200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06674076,  0.07898648,  0.01776453, ...,  0.09354263,\n",
       "         0.02024547,  0.00591952],\n",
       "       [ 0.11715547,  0.13860081,  0.03115709, ...,  0.16407703,\n",
       "         0.03568844,  0.01363267],\n",
       "       [ 0.10497413,  0.49519038,  0.02793387, ...,  0.14716771,\n",
       "         0.0321212 ,  0.01239527],\n",
       "       ..., \n",
       "       [ 0.08736103,  0.57987527,  0.02255858, ...,  0.12242479,\n",
       "         0.02671937,  0.00768929],\n",
       "       [ 0.08496009,  0.58979179,  0.02261483, ...,  0.11905934,\n",
       "         0.02592807,  0.00747984],\n",
       "       [ 0.61024956,  0.09214324,  0.02069834, ...,  0.10897716,\n",
       "         0.02359913,  0.0068488 ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict_proba(X_train[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.predict_proba(X_train[:200])[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45\n"
     ]
    }
   ],
   "source": [
    "print(model_pipe.score(X_test[:200], y_test[:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model on the entire train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('featureextractor', FeatureExtractor(column='Text')), ('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'...bability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83881134624\n"
     ]
    }
   ],
   "source": [
    "print(model_pipe.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.611872146119\n"
     ]
    }
   ],
   "source": [
    "print(model_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This was a first pass score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982440342188\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "# print(model_pipe.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neral Nets with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created new text_pipe to cut down on the number of features inputed in the neural net due to memory error.\n",
    "# There were 41028 features coming out of the CountVectorizer.\n",
    "\n",
    "text_pipe_k = make_pipeline(\n",
    "# FeatureExtractor('Text'),\n",
    "FunctionTransformer(lambda df: df['Text'], validate=False), \n",
    "CountVectorizer(stop_words='english'),\n",
    "TruncatedSVD(n_components=5000)\n",
    "# FunctionTransformer(lambda x: x.reshape(-1, 1)),\n",
    "# FunctionTransformer(lambda x: x.todense(), accept_sparse=True, validate=False)\n",
    ")\n",
    "\n",
    "fu = make_union(text_pipe_k, gene_pipe, var_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(input_dim=30):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5, seed=42)) # 50% dropout with 42 random state\n",
    "    model.add(Dense(9, activation='softmax')) # Activation function for the final output layer \n",
    "                                                             # needs to be softmax to accomidate the nine \n",
    "                                                             # different classes.\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def printX(X):\n",
    "#     print(X.shape)\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pipe_keras = make_pipeline(fu,\n",
    "# #                                  FunctionTransformer(printX),\n",
    "#                                  KerasClassifier(build_fn=create_model, input_dim=312, epochs=2, batch_size=10, verbose=1)\n",
    "#                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allows the number of features to be input automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ap = fu.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = KerasClassifier(build_fn=create_model, input_dim=X_train_ap.shape[1], epochs=10, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.fit(X_train_ap, y_train.values) # .values: pd df to numpy matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score of test of test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 0s 313us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.59491614e-01,   2.19694793e-01,   5.76639809e-02, ...,\n",
       "          1.25669599e-01,   2.95009073e-02,   8.57762843e-02],\n",
       "       [  2.23048404e-02,   1.77942496e-03,   7.50496387e-01, ...,\n",
       "          1.23288624e-01,   3.65310395e-03,   5.86872120e-05],\n",
       "       [  9.32567709e-05,   1.82996877e-02,   1.65729113e-02, ...,\n",
       "          9.58231330e-01,   1.29706677e-04,   5.35025247e-05],\n",
       "       ..., \n",
       "       [  2.31455397e-02,   5.56576587e-02,   1.42178787e-05, ...,\n",
       "          9.10925865e-01,   6.26178226e-03,   3.79859994e-05],\n",
       "       [  3.11045554e-08,   6.62461556e-16,   4.79166290e-11, ...,\n",
       "          2.34269646e-16,   4.88801662e-18,   4.04895186e-27],\n",
       "       [  4.17267710e-01,   1.83150098e-02,   1.79649413e-01, ...,\n",
       "          5.88812083e-02,   4.82242496e-04,   6.10550679e-03]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.predict_proba(fu.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 0s 405us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59086758333798417"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.score(fu.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score of test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5667/5667 [==============================] - 1s 233us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.94211595e-03,   5.39127961e-02,   1.04125720e-05, ...,\n",
       "          9.41870451e-01,   8.22879738e-05,   6.96811621e-05],\n",
       "       [  1.90934613e-01,   1.23797536e-01,   9.14123580e-02, ...,\n",
       "          6.66483790e-02,   2.22278889e-02,   3.98748778e-02],\n",
       "       [  2.18555533e-06,   9.86302257e-06,   3.13638289e-08, ...,\n",
       "          9.99973536e-01,   6.75220857e-09,   5.82818025e-08],\n",
       "       ..., \n",
       "       [  7.37759611e-03,   3.76747876e-01,   9.88245301e-06, ...,\n",
       "          6.06603563e-01,   3.03657464e-04,   2.30663922e-03],\n",
       "       [  7.76658803e-02,   4.78446931e-02,   6.24088794e-02, ...,\n",
       "          7.10803151e-01,   3.53051047e-03,   2.93173990e-03],\n",
       "       [  3.77911210e-01,   1.54853165e-02,   4.90666814e-02, ...,\n",
       "          4.71451432e-02,   1.33920405e-02,   2.13235188e-02]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.predict_proba(fu.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Not a gzipped file (b'7z')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-17373daf06c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Downloading target answers to test.csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_test_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/stage1_solution_filtered.csv.7z'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# df =             pd.read_csv('filename.tar.gz', compression='.xz', header=0, sep=',', quotechar='\"')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    703\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1682\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;31m# jump to the next member, if there is one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_gzip_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m_read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb'\\037\\213'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not a gzipped file (%r)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         (method, flag,\n",
      "\u001b[0;31mOSError\u001b[0m: Not a gzipped file (b'7z')"
     ]
    }
   ],
   "source": [
    "# Downloading target answers to test.csv\n",
    "\n",
    "# df_test_target = pd.read_csv('Data/stage1_solution_filtered.csv.7z', compression='gzip', header=0, sep=',', quotechar='\"')\n",
    "\n",
    "\n",
    "\n",
    "import libarchive.public\n",
    "\n",
    "with open('Data/stage1_solution_filtered.csv.7z', 'rb') as f:\n",
    "    buffer_ = f.read()\n",
    "    with libarchive.public.memory_reader(buffer_) as e:\n",
    "        for entry in e:\n",
    "            with open('/tmp/' + str(entry), 'wb') as f:\n",
    "                for block in entry.get_blocks():\n",
    "                    f.write(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.score(fu.transform(_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28725799189554257"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts().max()/y_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got model to work, but above code allows the number of features to be input automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 11.9615 - acc: 0.1400\n",
      "Epoch 2/2\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 10.2135 - acc: 0.2250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function <lambda> at 0x14a17d158>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pa...ts=None)), ('kerasclassifier', <keras.wrappers.scikit_learn.KerasClassifier object at 0x1489150f0>)])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipe_keras.fit(X_train[:200], y_train[:200].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be deleted and was the process to get to the working pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-e202cbece633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     ('cvec',CountVectorizer(['Text'])),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'gene'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gene'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'var'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Variation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "# allows naming of the unions (and weighting of transformers), takes a list of tuples\n",
    "combine_features_union = FeatureUnion([\n",
    "#     ('cvec',CountVectorizer(['Text'])),\n",
    "    ('gene', CategoricalExtractor('Gene')),\n",
    "    ('var', FeatureExtractor('Variation'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cfu', combine_features_union),\n",
    "    ('cvec',TfidfVectorizer(stop_words='english')),\n",
    "    ('clf_gs',OneVsRestClassifier(estimator=SVC(random_state=0)))]) #SVC(kernel='linear').set_params(probability=True)))])\n",
    "\n",
    "# grid ={'cvec':[CountVectorizer(), TfidfVectorizer()],\n",
    "#     'cvec__stop_words': [None, 'english'],\n",
    "#     'clf_gs':[OneVsRestClassifier(estimator=SVC(random_state=0))]}\n",
    "\n",
    "# pipe_gs = GridSearchCV(pipe, param_grid=grid)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# pipeGS = Pipeline([\n",
    "#     ('cfu', combine_features_union),\n",
    "#     ('ss', StandardScaler()),\n",
    "#     ('clf_gs', GridSearchCV(RandomForestClassifier(),param_grid={}))\n",
    "# ])\n",
    "\n",
    "# # define the grid search that controls the named pipeline objects\n",
    "# grid = {\n",
    "#     # clean up the ss\n",
    "#     'ss':[StandardScaler()],\n",
    "#     'clf_gs':[GridSearchCV(KNeighborsClassifier(),\n",
    "#                          param_grid={'n_neighbors':[3,6,9]}),\n",
    "#             GridSearchCV(RandomForestClassifier(),\n",
    "#                          param_grid={'n_estimators':np.arange(20,120,20),\n",
    "#                                      'max_depth':np.arange(5,30,5)})\n",
    "#            ]\n",
    "# }\n",
    "\n",
    "# # create grid search object with above grid searching parameters and fit\n",
    "# gs = GridSearchCV(pipeGS,param_grid=grid)\n",
    "# gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cfu', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input=['Text'],\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)), ('gene', CategoricalExtractor(column='Gene')), ('var', FeatureExtractor(column='Variation'))],\n",
       "         transformer_weights=None)),\n",
       " ('cvec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('clf_gs',\n",
       "  OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "    tol=0.001, verbose=False),\n",
       "            n_jobs=1))]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the best model params to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 2225, expected 3.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-1d40af031c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Hallie/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Hallie/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Hallie/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transformer_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Hallie/anaconda3/lib/python3.6/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Hallie/anaconda3/lib/python3.6/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    577\u001b[0m                                                     \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                                                     got=A.shape[0]))\n\u001b[0;32m--> 579\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbcol_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 2225, expected 3."
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train[], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Processing text\n",
    "# vec = CountVectorizer(stop_words='english')\n",
    "# vec.fit(X_train)\n",
    "# X_tfidf = vec.transform(X_train)\n",
    "# X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Just trying to get a rough model working\n",
    "\n",
    "# OvR = OneVsRestClassifier(SVC(kernel='linear').set_params(probability=True))\n",
    "# OvR.fit(X_tfidf, y_train)\n",
    "# # OvR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Trying modeling only using text in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
       "1   Abstract Background  Non-small cell lung canc...\n",
       "2   Abstract Background  Non-small cell lung canc...\n",
       "3  Recent evidence has demonstrated that acquired...\n",
       "4  Oncogenic mutations in the monomeric Casitas B..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_var.merge(train_txt ,on='ID')\n",
    "X = df[[ 'Text']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class1  class2  class3  class4  class5  class6  class7  class8  class9\n",
       "0       1       0       0       0       0       0       0       0       0\n",
       "1       0       1       0       0       0       0       0       0       0\n",
       "2       0       1       0       0       0       0       0       0       0\n",
       "3       0       0       1       0       0       0       0       0       0\n",
       "4       0       0       0       1       0       0       0       0       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Class']\n",
    "y = pd.get_dummies(y, prefix='class', prefix_sep='', columns=['Class'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 1) (3155, 1) (166, 9) (3155, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.95, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer(['Text']).fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38660</th>\n",
       "      <th>38661</th>\n",
       "      <th>38662</th>\n",
       "      <th>38663</th>\n",
       "      <th>38664</th>\n",
       "      <th>38665</th>\n",
       "      <th>38666</th>\n",
       "      <th>38667</th>\n",
       "      <th>38668</th>\n",
       "      <th>38669</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      0      2      0      0      0      0      0      0      0      0   \n",
       "1      0      2      0      0      0      0      0      4      0      0   \n",
       "\n",
       "   ...    38660  38661  38662  38663  38664  38665  38666  38667  38668  38669  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[2 rows x 38670 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(CountVectorizer().fit_transform(X_train['Text']).todense()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec',CountVectorizer()),\n",
    "    ('clf_gs',OneVsRestClassifier(estimator=SVC(random_state=0)))]) #SVC(kernel='linear').set_params(probability=True)))])\n",
    "\n",
    "# grid ={'cvec':[CountVectorizer(), TfidfVectorizer()],\n",
    "#     'cvec__stop_words': [None, 'english'],\n",
    "#     'clf_gs':[OneVsRestClassifier(estimator=SVC(random_state=0))]}\n",
    "\n",
    "# pipe_gs = GridSearchCV(pipe, param_grid=grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('clf_gs',\n",
       "  OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "    tol=0.001, verbose=False),\n",
       "            n_jobs=1))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
    "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
    "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
    "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "          tokenizer=None, vocabulary=None)),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Tuberous sclerosis complex (TSC) is an autosom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>Summary Hepatocellular adenomas (HCA) are beni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Cell division is controlled by a series of pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Purpose: Epidermal growth factor receptor (EGF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>EML4–ALK fusions define a subset of lung cance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "993   Tuberous sclerosis complex (TSC) is an autosom...\n",
       "2308  Summary Hepatocellular adenomas (HCA) are beni...\n",
       "688   Cell division is controlled by a series of pos...\n",
       "246   Purpose: Epidermal growth factor receptor (EGF...\n",
       "1512  EML4–ALK fusions define a subset of lung cance..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class1  class2  class3  class4  class5  class6  class7  class8  class9\n",
       "993        0       0       0       1       0       0       0       0       0\n",
       "2308       0       0       0       0       0       0       1       0       0\n",
       "688        0       0       0       1       0       0       0       0       0\n",
       "246        0       0       0       0       0       0       1       0       0\n",
       "1512       0       1       0       0       0       0       0       0       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hallie/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 7 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...robability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train['Text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
