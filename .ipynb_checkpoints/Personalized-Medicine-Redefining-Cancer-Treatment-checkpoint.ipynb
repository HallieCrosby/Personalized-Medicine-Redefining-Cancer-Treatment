{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, \\\n",
    "HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline, make_pipeline, make_union\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_var = pd.read_csv('Data/training_variants.zip')\n",
    "train_txt = pd.read_csv('Data/training_text.zip', sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n",
    "test_var = pd.read_csv('Data/test_variants.zip')\n",
    "test_txt = pd.read_csv('Data/test_text.zip', sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining variant and text training dataframes, drop null rows, and then split into X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_var.merge(train_txt, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Gene', 'Variation', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Test text and Test var dataframes\n",
    "df_test = test_var.merge(test_txt, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null columns\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_target = pd.read_csv('Data/stage1_solution_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_reduced = df_test_target.merge(df_test, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_reduced.shape)\n",
    "df_test_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_reduced.rename(columns={'class1': \"1\", 'class2': \"2\", 'class3': \"3\", 'class4': \"4\", 'class5': \"5\", 'class6': '6', 'class7': \"7\", 'class8': \"8\", 'class9': \"9\"}, inplace=True)\n",
    "df_test_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_y = df_test_reduced.drop(['ID','Gene','Variation','Text'], axis=1).idxmax(axis=1)\n",
    "print(test_set_y.shape)\n",
    "test_set_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_X = df_test_reduced.drop(['ID','1','2','3','4','5','6','7','8','9'], axis=1)\n",
    "print(test_set_X.shape)\n",
    "test_set_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    One-hot-encodes a categorical (string) column.\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.values = None\n",
    "        \n",
    "    def _create_values(self, indices):\n",
    "        return {ind: i+1 for i, ind in enumerate(indices)}\n",
    "    \n",
    "    def _apply_values(self, row_val):\n",
    "        return self.values.get(row_val, 0)\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.values = self._create_values(X[self.column].value_counts().index)\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        col = X[self.column].apply(self._apply_values)\n",
    "        return col.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neral Nets with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pipelines\n",
    "\n",
    "gene_pipe = make_pipeline(\n",
    "CategoricalExtractor('Gene'),\n",
    "OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "var_pipe = make_pipeline(\n",
    "CategoricalExtractor('Variation'),\n",
    "OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "text_pipe_k = make_pipeline(\n",
    "FunctionTransformer(lambda df: df['Text'], validate=False), \n",
    "CountVectorizer(stop_words='english'),\n",
    "TruncatedSVD(n_components=5000)\n",
    ")\n",
    "\n",
    "fu = make_union(text_pipe_k, gene_pipe, var_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(input_dim=30):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.5, seed=42)) # 50% dropout with 42 random state\n",
    "    model.add(Dense(9, activation='softmax')) # Activation function for the final output layer \n",
    "                                                             # needs to be softmax to accomidate the nine \n",
    "                                                             # different classes.\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows the number of features to be input automatically.\n",
    "X_train_ap = fu.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = KerasClassifier(build_fn=create_model, input_dim=X_train_ap.shape[1], epochs=10, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.fit(X_train_ap, y_train.values) # .values: pd df to numpy matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Score of test of test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 0s 313us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.59491614e-01,   2.19694793e-01,   5.76639809e-02, ...,\n",
       "          1.25669599e-01,   2.95009073e-02,   8.57762843e-02],\n",
       "       [  2.23048404e-02,   1.77942496e-03,   7.50496387e-01, ...,\n",
       "          1.23288624e-01,   3.65310395e-03,   5.86872120e-05],\n",
       "       [  9.32567709e-05,   1.82996877e-02,   1.65729113e-02, ...,\n",
       "          9.58231330e-01,   1.29706677e-04,   5.35025247e-05],\n",
       "       ..., \n",
       "       [  2.31455397e-02,   5.56576587e-02,   1.42178787e-05, ...,\n",
       "          9.10925865e-01,   6.26178226e-03,   3.79859994e-05],\n",
       "       [  3.11045554e-08,   6.62461556e-16,   4.79166290e-11, ...,\n",
       "          2.34269646e-16,   4.88801662e-18,   4.04895186e-27],\n",
       "       [  4.17267710e-01,   1.83150098e-02,   1.79649413e-01, ...,\n",
       "          5.88812083e-02,   4.82242496e-04,   6.10550679e-03]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent likelyhood for each target\n",
    "model_keras.predict_proba(fu.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095/1095 [==============================] - 0s 405us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.59086758333798417"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.score(fu.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Test set score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent likelyhood for each target\n",
    "model_keras.predict_proba(fu.transform(test_set_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.score(fu.transform(test_set_X), test_set_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Baseline accuracy based on traning data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28709288299155611"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().max()/y.value_counts().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
